# CVPR 2021


## [List of CVPR 2021 Tutorials and Workshop](https://www.reddit.com/r/computervision/comments/oa5z3o/list_of_cvpr_2021_tutorials_and_workshop/)

1. [Language for 3D Scenes](https://youtube.com/playlist?list=PLEIhq70yQhTACmNbXjFkA_yYTtR6LE8BR)

2. [Frontiers of Monocular 3D Perception](https://youtube.com/playlist?list=PLEIhq70yQhTDNvBPbec-Z1BgF5S22I3p6)
3. [Beyond Fairness: Towards a Just, Equitable, and Accountable Computer Vision](https://youtube.com/playlist?list=PLEIhq70yQhTCNF9oGxL1Xx3WQn8ddlP1m)
4. [Responsible Computer Vision](https://youtube.com/playlist?list=PLUgbVHjDharh-Vqk1K69uk7AUFKt9JTIl)
5. [Affective Understanding in Video](https://youtube.com/playlist?list=PLUgbVHjDharheJU376Upvk2DoBrmLYHdk)
6. [When Image Analysis Meets Natural Language Processing: A Case Study in Radiology](https://youtube.com/playlist?list=PLUgbVHjDhargV_dgD4TsNObumDvBcpAbm)
7. [New Frontiers in Data-Driven Autonomous Driving](https://youtube.com/playlist?list=PLUgbVHjDharjwxJUlbRObllPj-HRtTLTl)
8. [International Challenge on Activity Recognition (ActivityNet)](https://youtube.com/playlist?list=PLUgbVHjDharhwg2uM_hj5kiVnSpMZYDIW\)
9. [Medical Computer Vision](https://youtube.com/playlist?list=PLUgbVHjDharj9ttEepu-Vv3610-PCK9dK)
10. [International Workshop on Dynamic Scene Reconstruction](https://youtube.com/playlist?list=PLUgbVHjDharhGNLVoq2QkCalwTxIWkjWR)
11. [Workshop on Event-based Vision](https://youtube.com/playlist?list=PLUgbVHjDharj-uqu91nV_anULCfpQoi5b)
12. [New Frontiers in Data-Driven Autonomous Driving](https://youtube.com/playlist?list=PLUgbVHjDharjwxJUlbRObllPj-HRtTLTl)
13. [Cross-View and Cross-Modal Visual Geo-Localization](https://youtube.com/playlist?list=PLUgbVHjDharjTo9tk3xcPJHEkmi33ap-u)
14. [Data- and Label-Efficient Learning in An Imperfect World](https://youtube.com/playlist?list=PLUgbVHjDhari3K24ROdYth2OS4Y4hH028)
15. [From VQA to VLN: Recent Advances in Vision-and-Language Research](https://youtube.com/playlist?list=PLUgbVHjDhari645g1zmpo-MtOVap1FKxh)
16. [Autonomous Driving: Perception, Prediction and Planning](https://youtube.com/playlist?list=PLUgbVHjDhargdoZ9hLlKS6lJIYOqcYoND)
17. [Theory and Application of Energy-Based Generative Models](https://youtube.com/playlist?list=PLUgbVHjDharg7zIB00tCgk8dcrWLnWR0a)
18. [Adversarial Machine Learning in Computer Vision](https://youtube.com/playlist?list=PLUgbVHjDhargI044nRdTVQvc2p9-yORKL)
18. [Leave Those Nets Alone: Advances in Self-Supervised Learning: IEEE CVPR 2021 Tutorial](https://youtube.com/playlist?list=PLUgbVHjDharhcjvDURmtAeLSU84Vr2V-Q)
19. [Autonomous Driving: IEEE CVPR 2021 Tutorial](https://youtube.com/playlist?list=PLUgbVHjDharhCnUzWQryw2rZUe7K_qWdc)
20. [Normalization Techniques in Deep Learning: Methods, Analyses, and Applications: IEEE CVPR 2021 Tutorial](https://youtube.com/playlist?list=PLUgbVHjDhargycWpy2V1jdKto19YhTaTt)
21. [Fine-Grained Visual Categorization: IEEE CVPR 2021 Tutorial](https://youtube.com/playlist?list=PLUgbVHjDhargrqfiqGf8LlN4QeRnds-bP)
22. [Binary Networks for Computer Vision: IEEE CVPR 2021 Workshop](https://youtube.com/playlist?list=PLEIhq70yQhTAdoVAuHUdSR-xQHXzATgYo)


## Some papers that are worth exploring
Here is the list of all CVPR 2021 (Conference on Computer Vision and Pattern Recognition) papers, and a one sentence highlight for each of them

1. [Highlights](https://www.paperdigest.org/2021/06/cvpr-2021-highlights)
2. [There are more than 300 papers with code/data published](https://www.paperdigest.org/2021/06/cvpr-2021-papers-with-code-data/)

1. [Invertible Denoising Network: A Light Solution for Real Noise Removal](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Invertible_Denoising_Network_A_Light_Solution_for_Real_Noise_Removal_CVPR_2021_paper.pdf). This can be used to understand the noises in image and its removing approaches.

2. [Points As Queries: Weakly Semi-Supervised Object Detection by Points](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Points_As_Queries_Weakly_Semi-Supervised_Object_Detection_by_Points_CVPR_2021_paper.pdf): They proposed a novel point annotated setting for the weakly semi-supervised object detection task, in which the dataset comprises small fully annotated images and large weakly annotated images by points.
3. [Monocular Depth Estimation via Listwise Ranking Using the Plackett-Luce Model](https://openaccess.thecvf.com/content/CVPR2021/papers/Lienen_Monocular_Depth_Estimation_via_Listwise_Ranking_Using_the_Plackett-Luce_Model_CVPR_2021_paper.pdf): This can be used to explore to use in Single Camera based Measure and Pepsi Dispencer like projects

4. [AdaBins: Depth Estimation Using Adaptive Bins](https://openaccess.thecvf.com/content/CVPR2021/papers/Bhat_AdaBins_Depth_Estimation_Using_Adaptive_Bins_CVPR_2021_paper.pdf):
  We address the problem of estimating a high quality dense depth map from a single RGB input image. We start out with a baseline encoder-decoder convolutional neural network architecture and pose the question of how the global processing of information can help improve overall depth estimation. To this end, we propose a transformer-based architecture block that divides the depth range into bins whose center value is estimated adaptively per image. The final depth values are estimated as linear combinations of the bin centers. We call our new building block AdaBins. Our results show a decisive improvement over the state-of-the-art on several popular depth datasets across all metrics. We also validate the effectiveness of the proposed block with an ablation study and provide the code and corresponding pre-trained weights of the new state-of-the-art model.

5. [Learning To Count Everything](https://openaccess.thecvf.com/content/CVPR2021/papers/Ranjan_Learning_To_Count_Everything_CVPR_2021_paper.pdf):
  Existing works on visual counting primarily focus on one specific category at a time, such as people, animals, and cells. In this paper, we are interested in counting everything, that is to count objects from any category given only a few annotated instances from that category. To this end, we pose counting as a few-shot regression task. To tackle this task, we present a novel method that takes a query image together with a few exemplar objects from the query image and predicts a density map for the presence of all objects of interest in the query image. We also present a novel adaptation strategy to adapt our network to any novel visual category at test time, using only a few exemplar objects from the novel category. We also introduce a dataset of 147 object categories containing over 6000 images that are suitable for the few-shot counting task. The images are annotated with two types of annotation, dots and bounding boxes, and they can be used for developing few-shot counting models. Experiments on this dataset shows that our method outperforms several state-of-the-art object detectors and few-shot counting approaches. Our code and dataset can be found [here](https://github.com/cvlab-stonybrook/LearningToCountEverything).

6. [When Human Pose Estimation Meets Robustness: Adversarial Algorithms and Benchmarks](http://openaccess.thecvf.com//content/CVPR2021/html/Wang_When_Human_Pose_Estimation_Meets_Robustness_Adversarial_Algorithms_and_Benchmarks_CVPR_2021_paper.html):
  his work comprehensively studies and addresses this problem by building rigorous robust benchmarks, termed COCO-C, MPII-C, and OCHuman-C, to evaluate the weaknesses of current advanced pose estimators, and a new algorithm termed AdvMix is proposed to improve their robustness in different corruptions.

7. [Detection, Tracking, and Counting Meets Drones in Crowds: A Benchmark](http://openaccess.thecvf.com//content/CVPR2021/html/Wen_Detection_Tracking_and_Counting_Meets_Drones_in_Crowds_A_Benchmark_CVPR_2021_paper.html):
  To promote the developments of object detection, tracking and counting algorithms in drone-captured videos, we construct a benchmark with a new drone-captured large-scale dataset, named as DroneCrowd, formed by 112 video clips with 33,600 HD frames in various scenarios.

8. [Depth From Camera Motion and Object Detection](http://openaccess.thecvf.com//content/CVPR2021/html/Griffin_Depth_From_Camera_Motion_and_Object_Detection_CVPR_2021_paper.html):
  This paper addresses the problem of learning to estimate the depth of detected objects given some measurement of camera motion (e.g., from robot kinematics or vehicle odometry).

9. [A Generalized Loss Function for Crowd Counting and Localization](http://openaccess.thecvf.com//content/CVPR2021/html/Wan_A_Generalized_Loss_Function_for_Crowd_Counting_and_Localization_CVPR_2021_paper.html):
  In this paper, we investigate learning the density map representation through an unbalanced optimal transport problem, and propose a generalized loss function to learn density maps for crowd counting and localization.

10. [Have a look: They published a paper on CVPR2021](https://www.youtube.com/watch?v=CPHC7TljskY&list=PLEIhq70yQhTAdoVAuHUdSR-xQHXzATgYo&index=1)
  * [Larq](https://github.com/larq/larq) is an open-source deep learning library for training neural networks with extremely low precision weights and activations, such as Binarized Neural Networks (BNNs).

  * [Larq Compute Engine (LCE)](https://github.com/larq/compute-engine) is a highly optimized inference engine for deploying extremely quantized neural networks, such as Binarized Neural Networks (BNNs). LCE currently supports 64-bit ARM-based mobile platforms such as Android phones and Raspberry Pi boards (64bit Arm Based Boards).

  * [Larq Zoo](https://docs.larq.dev/zoo/) provides reference implementations of deep neural networks with extremely low precision weights and activations that are made available alongside pre-trained weights. These models can be used for prediction, feature extraction, and fine-tuning.
